{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fitted-night",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "from glob import glob\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "from make_tfrecord import MakeTFRecord\n",
    "from preprocessing import delete_mat, delete_4_channel, label_encoding\n",
    "from dataloader import TFRecordLoader\n",
    "from model import MakeModel\n",
    "\n",
    "\n",
    "def preprocessing_1(data_path):\n",
    "    data_path = data_path + \"*\"\n",
    "    data_list = glob(data_path)\n",
    "    \n",
    "    # 전처리\n",
    "    data_list = delete_mat(data_list)\n",
    "    data_list = delete_4_channel(data_list)\n",
    "\n",
    "    data_class = label_encoding(data_list)\n",
    "    return data_list, data_class\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--mode\", choices=[\"tfr\", \"train\", \"test\"], help=\"TFRecord만들기 or 모델학습 or 모델테스트\")\n",
    "    parser.add_argument(\"--data_path\", type=str, default=\"./\", help=\"데이터가 들어있는 디렉토리 경로\")\n",
    "    parser.add_argument(\"--tfr_path\", type=str, default=\"./\", help=\"tfrecord가 저장될 디렉토리\")\n",
    "    parser.add_argument(\"--img_size\", type=int, default=224, help=\"이미지 사이즈 입력\")\n",
    "    parser.add_argument(\"--epoch\", type=int, default=20, help=\"에포크 수 입력\")\n",
    "    parser.add_argument(\"--batch_size\", type=int, default=32, help=\"배치 크기 입력\")\n",
    "    parser.add_argument(\"patience\", type=int, default=1, help=\"몇 번 참을 것인가?\")\n",
    "    parser.add_argument(\"--model_path\", type=str, default=\"./\", help=\"모델이 저장될 경로\")\n",
    "    parser.add_argument(\"--train_size_rate\", type=float, default=0.8, help=\"학습 데이터 비율 입력\")\n",
    "    parser.add_argument(\"--model_name\", choices=[\"e0\", \"mobilev2\"], default=\"e0\", help=)\"불러올 모델 이름 입력\"\n",
    "    parser.add_argument(\"--add_layer\", type=str, nargs=\"+\", help=\"dense or batch\")\n",
    "    parser.add_argument(\"--dense_nums\", nargs=\"+\", help=\"dense의 뉴런 수 입력\")\n",
    "    parser.add_argument(\"--dense_activation\", nargs=\"+\", help=\"activation function 입력\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    \n",
    "    data_list, data_class = preprocessing_1(args.data_path)\n",
    "    if args.mode == \"tfr\":\n",
    "       \n",
    "        IMG_SIZE = args.img_size\n",
    "        tfrecord = MakeTFRecord(\n",
    "            data_list = data_list,\n",
    "            tfr_path = args.tfr_path,\n",
    "            data_class = data_class\n",
    "        )\n",
    "\n",
    "        if args.img_size != 224:\n",
    "            tfrecord.change_img_size(args.img_size)\n",
    "        # tfrecord 만들기\n",
    "        tfrecord()\n",
    "\n",
    "    elif args.mode == \"train\":\n",
    "        # hyper parameters\n",
    "        epoch = args.epoch\n",
    "        batch_size = args.batch_size\n",
    "        early_stopping = tf.keras.callbacks.EarlyStopping(patience=args.patience)\n",
    "        model_save = tf.keras.callbacks.ModelCheckpoint(\n",
    "            filepath=args.model_path,\n",
    "            monitor='val_loss',\n",
    "            save_best_only=True,\n",
    "            verbose=1\n",
    "        )\n",
    "\n",
    "        # dataload\n",
    "        data_load = TFRecordLoader(\n",
    "            args.tfr_path,\n",
    "            args.img_size,\n",
    "            len(data_class),\n",
    "            args.train_size_rate,\n",
    "            batch_size\n",
    "        )\n",
    "\n",
    "        train, valid, steps = data_load()\n",
    "\n",
    "        # make model\n",
    "        make_model = MakeModel(args.model_name)\n",
    "        # 추가할 layer\n",
    "        layers = ()\n",
    "\n",
    "        # [\"dense,batch,dense\"]\n",
    "        # [\"dense,batch,dense\"],\n",
    "\n",
    "        args.add_layer = args.add_layer[0].split(\",\")\n",
    "        args.dense_nums = args.dense_nums[0].split(\",\")\n",
    "        args.dense_activation = args.dense_activation[0].split(\",\")\n",
    "\n",
    "        # layer 추가\n",
    "        for layer in args.add_layer:\n",
    "            if layer == \"dense\":\n",
    "                nums = int(args.dense_nums[0])\n",
    "                activation = args.dense_activation[0]\n",
    "                layers += (make_model.add_dense_layer(nums, activation))\n",
    "\n",
    "                args.dense_nums.pop(0)\n",
    "                args.dense_activation.pop(0)\n",
    "\n",
    "            elif layer == \"batch\":\n",
    "                layers += (make_model.add_batch_norm())\n",
    "\n",
    "            else:\n",
    "                raise ValueError(\"dense or batch만 입력\")\n",
    "\n",
    "        model = make_model.make_model_with_FCL(args.img_size, layers)\n",
    "\n",
    "        # optimizer = args.optimizer\n",
    "        # loss = args.loss\n",
    "\n",
    "        model.compile(\n",
    "            optimizer='adam',\n",
    "            loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "            metrics=[\"accuracy\"]\n",
    "        )\n",
    "\n",
    "        history = model.fit(\n",
    "            train,\n",
    "            validation_data=valid,\n",
    "            steps_per_epoch=steps,\n",
    "            epochs=epoch,\n",
    "            callbacks=[early_stopping, model_save]\n",
    "        )\n",
    "\n",
    "        hist = pd.DataFrame(history.history)\n",
    "        hist.to_pickle(args.hist_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

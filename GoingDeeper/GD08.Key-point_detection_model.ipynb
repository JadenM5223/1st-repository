{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 필요 라이브러리 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pretrained image feature embedding을 활용한 fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23712 23712\n",
      "Found 23712 images belonging to 1 classes.\n",
      "Found 23712 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "home_dir = os.getenv('HOME')+'/lfw'\n",
    "list_image = sorted(glob.glob(home_dir+'/data/train/input/img/*.png'))\n",
    "list_label = sorted(glob.glob(home_dir+'/data/train/label/mask/*.png'))\n",
    "print (len(list_image), len(list_label))\n",
    "\n",
    "# 32의 배수를 벗어나는 파일 경로들을 담은 list\n",
    "list_image_out_of_range = list_image[len(list_image) - (len(list_image) % 32):]\n",
    "list_label_out_of_range = list_label[len(list_label) - (len(list_label) % 32):]\n",
    "\n",
    "# 해당 list가 존재한다면, 파일 삭제\n",
    "if list_image_out_of_range:\n",
    "    for path in list_image_out_of_range:\n",
    "        os.remove(path)\n",
    "if list_label_out_of_range:\n",
    "    for path in list_label_out_of_range:\n",
    "        os.remove(path)\n",
    "\n",
    "IMAGE_SHAPE = (80, 120)\n",
    "data_root = home_dir+'/data/train/input'\n",
    "label_root = home_dir+'/data/train/label'\n",
    "\n",
    "image_generator = tf.keras.preprocessing.image.ImageDataGenerator()\n",
    "label_generator = tf.keras.preprocessing.image.ImageDataGenerator()\n",
    "image_data = image_generator.flow_from_directory(str(data_root), class_mode=None, target_size=IMAGE_SHAPE, batch_size=32)\n",
    "label_data = label_generator.flow_from_directory(str(label_root), class_mode=None, target_size=IMAGE_SHAPE, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_generation(train_generator, label_generator):\n",
    "    h, w = train_generator.target_size\n",
    "    for images, labels in zip(train_generator, label_generator):\n",
    "        images /= 255.\n",
    "        images = images[..., ::-1] # rgb to bgr\n",
    "\n",
    "        list_point_labels = []\n",
    "        for img, label in zip(images, labels):\n",
    "\n",
    "            eye_ls = np.where(label==1) # leftside\n",
    "            eye_rs = np.where(label==2) # rightside\n",
    "            eye_center = np.where(label==3)\n",
    "\n",
    "            lx, ly = [eye_ls[1].mean(), eye_ls[0].mean()]\n",
    "            rx, ry = [eye_rs[1].mean(), eye_rs[0].mean()]\n",
    "            cx, cy = [eye_center[1].mean(), eye_center[0].mean()]\n",
    "\n",
    "            if len(eye_ls[0])==0 or len(eye_ls[1])==0:\n",
    "                lx, ly = [0, 0]\n",
    "            if len(eye_rs[0])==0 or len(eye_rs[1])==0:\n",
    "                rx, ry = [w, h]\n",
    "            if len(eye_center[0])==0 or len(eye_center[1])==0:\n",
    "                cx, cy = [0, 0]\n",
    "\n",
    "            np_point_label = np.array([lx/w,ly/h,rx/w,ry/h,cx/w,cy/h], dtype=np.float32)\n",
    "\n",
    "            list_point_labels.append(np_point_label)\n",
    "        np_point_labels = np.array(list_point_labels)\n",
    "        yield (images, np_point_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator로 데이터 포인트 뽑기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80, 120, 3) [0.         0.         1.         1.         0.43333334 0.46722442]\n",
      "(80, 120, 3) [0.         0.         1.         1.         0.70416665 0.375     ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aiffel/anaconda3/envs/aiffel/lib/python3.7/site-packages/ipykernel_launcher.py:14: RuntimeWarning: Mean of empty slice.\n",
      "  \n",
      "/home/aiffel/anaconda3/envs/aiffel/lib/python3.7/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/aiffel/anaconda3/envs/aiffel/lib/python3.7/site-packages/ipykernel_launcher.py:15: RuntimeWarning: Mean of empty slice.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "user_train_generator = user_generation(image_data, label_data)\n",
    "for i in range(2):\n",
    "    dd = next(user_train_generator)\n",
    "    print (dd[0][0].shape, dd[1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 2048)\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "keras_layer (KerasLayer)     (None, 2048)              23564800  \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 6)                 12294     \n",
      "=================================================================\n",
      "Total params: 23,577,094\n",
      "Trainable params: 12,294\n",
      "Non-trainable params: 23,564,800\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "''' tf hub feature_extractor '''\n",
    "feature_extractor_url = \"https://tfhub.dev/google/imagenet/resnet_v2_50/feature_vector/4\"\n",
    "feature_extractor_layer = hub.KerasLayer(feature_extractor_url,\n",
    "                                            input_shape=(80,120,3))\n",
    "\n",
    "image_batch = next(image_data)\n",
    "feature_batch = feature_extractor_layer(image_batch)\n",
    "print(feature_batch.shape)\n",
    "\n",
    "num_classes = 6\n",
    "\n",
    "feature_extractor_layer.trainable = False\n",
    "model = tf.keras.Sequential([\n",
    "    feature_extractor_layer,\n",
    "    #layers.Dense(1024, activation='relu'),\n",
    "    #layers.Dropout(0.5),\n",
    "    layers.Dense(num_classes, activation='sigmoid'),\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(),\n",
    "  loss='mse',\n",
    "  metrics=['mae']\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습률 조절 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_step_decay(epoch):\n",
    "      init_lr = 0.0005 #self.flag.initial_learning_rate\n",
    "      lr_decay = 0.5 #self.flag.learning_rate_decay_factor\n",
    "      epoch_per_decay = 2 #self.flag.epoch_per_decay\n",
    "      lrate = init_lr * math.pow(lr_decay, math.floor((1+epoch)/epoch_per_decay))\n",
    "      return lrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23712 32 741\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aiffel/anaconda3/envs/aiffel/lib/python3.7/site-packages/ipykernel_launcher.py:14: RuntimeWarning: Mean of empty slice.\n",
      "  \n",
      "/home/aiffel/anaconda3/envs/aiffel/lib/python3.7/site-packages/ipykernel_launcher.py:15: RuntimeWarning: Mean of empty slice.\n",
      "  from ipykernel import kernelapp as app\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 741 steps\n",
      "Epoch 1/10\n",
      "  5/741 [..............................] - ETA: 5:34 - loss: 0.2085 - mae: 0.3672"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aiffel/anaconda3/envs/aiffel/lib/python3.7/site-packages/ipykernel_launcher.py:14: RuntimeWarning: Mean of empty slice.\n",
      "  \n",
      "/home/aiffel/anaconda3/envs/aiffel/lib/python3.7/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/aiffel/anaconda3/envs/aiffel/lib/python3.7/site-packages/ipykernel_launcher.py:15: RuntimeWarning: Mean of empty slice.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "741/741 [==============================] - 43s 57ms/step - loss: 0.0192 - mae: 0.0685\n",
      "Epoch 2/10\n",
      "741/741 [==============================] - 24s 32ms/step - loss: 0.0143 - mae: 0.0562\n",
      "Epoch 3/10\n",
      "741/741 [==============================] - 23s 31ms/step - loss: 0.0137 - mae: 0.0546\n",
      "Epoch 4/10\n",
      "741/741 [==============================] - 23s 31ms/step - loss: 0.0132 - mae: 0.0533\n",
      "Epoch 5/10\n",
      "741/741 [==============================] - 23s 31ms/step - loss: 0.0131 - mae: 0.0530\n",
      "Epoch 6/10\n",
      "741/741 [==============================] - 23s 31ms/step - loss: 0.0129 - mae: 0.0526\n",
      "Epoch 7/10\n",
      "741/741 [==============================] - 22s 30ms/step - loss: 0.0129 - mae: 0.0523\n",
      "Epoch 8/10\n",
      "741/741 [==============================] - 23s 32ms/step - loss: 0.0128 - mae: 0.0521\n",
      "Epoch 9/10\n",
      "741/741 [==============================] - 22s 30ms/step - loss: 0.0128 - mae: 0.0521\n",
      "Epoch 10/10\n",
      "741/741 [==============================] - 23s 31ms/step - loss: 0.0127 - mae: 0.0519\n"
     ]
    }
   ],
   "source": [
    "steps_per_epoch = image_data.samples//image_data.batch_size\n",
    "print (image_data.samples, image_data.batch_size, steps_per_epoch)\n",
    "# 23712 32 741 -> 데이터를 batch_size(32) 의 배수로 맞춰 준비해 주세요. \n",
    "\n",
    "assert(image_data.samples % image_data.batch_size == 0)  # 데이터가 32의 배수가 되지 않으면 model.fit()에서 에러가 발생합니다.\n",
    "\n",
    "learning_rate = LearningRateScheduler(lr_step_decay)\n",
    "\n",
    "history = model.fit(user_train_generator, epochs=10,\n",
    "                    steps_per_epoch=steps_per_epoch,\n",
    "                    callbacks = [learning_rate]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2628 images belonging to 1 classes.\n",
      "Found 2628 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "IMAGE_SHAPE = (80, 120)\n",
    "\n",
    "home_dir = os.getenv('HOME')+'/lfw'\n",
    "\n",
    "val_data_root = home_dir + '/data/val/input'\n",
    "val_label_root = home_dir + '/data/val/label'\n",
    "\n",
    "image_generator_val = tf.keras.preprocessing.image.ImageDataGenerator()\n",
    "label_generator_val = tf.keras.preprocessing.image.ImageDataGenerator()\n",
    "image_data_val = image_generator.flow_from_directory(str(val_data_root), class_mode=None, target_size=IMAGE_SHAPE, shuffle=False)\n",
    "label_data_val = label_generator.flow_from_directory(str(val_label_root), class_mode=None, target_size=IMAGE_SHAPE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-10-65e239844661>:2: Model.evaluate_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.evaluate, which supports generators.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-10-65e239844661>:2: Model.evaluate_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.evaluate, which supports generators.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aiffel/anaconda3/envs/aiffel/lib/python3.7/site-packages/ipykernel_launcher.py:14: RuntimeWarning: Mean of empty slice.\n",
      "  \n",
      "/home/aiffel/anaconda3/envs/aiffel/lib/python3.7/site-packages/ipykernel_launcher.py:15: RuntimeWarning: Mean of empty slice.\n",
      "  from ipykernel import kernelapp as app\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.012282416542492262 0.05072564\n"
     ]
    }
   ],
   "source": [
    "user_val_generator = user_generation(image_data_val, label_data_val)\n",
    "mse, mae = model.evaluate_generator(user_val_generator, image_data_val.n // 32)\n",
    "print(mse, mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 이미지 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# img test\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = cv2.imread(val_data_root+'/img/eye_000010_l.png')\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[  7.3846216   3.1819608]\n",
      "  [114.17871    77.43669  ]\n",
      "  [ 53.31192    27.496355 ]]]\n"
     ]
    }
   ],
   "source": [
    "np_inputs = np.expand_dims(cv2.resize(img, (120, 80)), axis=0)\n",
    "preds = model.predict(np_inputs/255., 1)\n",
    "\n",
    "repred = preds.reshape((1, 3, 2))\n",
    "repred[:,:,0] *= 120\n",
    "repred[:,:,1] *= 80\n",
    "print (repred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7. 3.]\n",
      "[114.  77.]\n",
      "[53. 27.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show = img.copy()\n",
    "for pt in repred[0]:\n",
    "    print (pt.round())\n",
    "    show = cv2.circle(show, tuple((pt*0.5).astype(int)), 3, (0,255,255), -1)\n",
    "\n",
    "plt.imshow(cv2.cvtColor(show, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
